{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework1_updated.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annykay/scientificComputations/blob/main/Homework1_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZolClXS9vzz"
      },
      "source": [
        "#### Changelog\n",
        "\n",
        "1. Q13.3 How many clams that are wider than 0.4, have first name \"Monster\"?   \n",
        "2. Q13.4 What was the second name of a clam captured at March, 8, that was longer than 0.65 and wider than 0.57?\n",
        "3. Q15.2 Create a new column `area` using diameter, length and considering that a clam is a perfect rectangle.\n",
        "4. Q19.4 `density_by_age` groupby `age_cat` and compute average density of a clam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fengSNSWl1X"
      },
      "source": [
        "# Assignment 1. Sea Ears.\n",
        "by Anvar Kurmukov,\n",
        "updated by Bogdan Kirillov\n",
        "\n",
        "---\n",
        "\n",
        "By the end of this task you will be able to manipulate huge tabular data:\n",
        "1. Compute different column's statistics (min, max, mean, quantiles etc.);\n",
        "2. Select observations/features by condition/index;\n",
        "3. Create new non-linear combinations of the columns (feature engineering);\n",
        "4. Perform automated data cleaning;\n",
        "\n",
        "and more.\n",
        "\n",
        "---\n",
        "\n",
        "For those who are not familiar with `pandas` we recommend these (alternative) tutorials:\n",
        "\n",
        "1. Single notebook, covers basic pandas functionality (starting with renaming columns ending with using map, apply etc) ~ 30 short examples with links on videos https://nbviewer.jupyter.org/github/justmarkham/pandas-videos/blob/master/pandas.ipynb . Highly recommended for everyone. (about 1-3 hours to go through)\n",
        "\n",
        "2. https://github.com/guipsamora/pandas_exercises/ 11 topics covering all essential functionality with excersises (with solutions).\n",
        "\n",
        "This task will be an easy ride after these tutorials.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBv4L3BoWtY8"
      },
      "source": [
        "We are using the data on a species of clam called abalone, also known as \"Sea ears\". This dataset is in public domain and can be obtained from Delve: http://www.cs.toronto.edu/~delve/data/abalone/desc.html For this task, we have modified the dataset slightly, so you could try out some complicated data manipulation techniques while keeping the dataset as simple as possible. So, in our case, each abalone clam is a promising rapper who is ready for a debut mixtape.\n",
        "\n",
        "You need to place \"sea_ears.csv\" file in the same directory as this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYmsZ_BQWx6a"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mp5vQW5Xtw5"
      },
      "source": [
        "# 1. Loading data\n",
        "\n",
        "As always in Data Science you are starting with making nice cup of tea (or coffee). Your next move is to load the data:\n",
        "\n",
        "- Start with loading `sea_ears.csv` file using `pd.read_csv()` function.\n",
        "- You may also want to increase maximal displayed pandas columns: set `pd.options.display.max_columns` to 30\n",
        "- Print top 10 observations in the table. `.head()`\n",
        "- Print last 10 observations in the table. `.tail()`\n",
        "- Print all the data columns names using method `.columns`\n",
        "- Print data size (number of rows and columns). This is the `.shape` of the data.\n",
        "\n",
        "*Almost* every python has a `head` and a `tail` just as DataFrames do.\n",
        "\n",
        "If you are using Google Colab, you can upload the file in the cell below. If you are NOT using Colab, set COLAB_P in the cell below to False."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS_2J7IXX9ZS",
        "outputId": "8c802dc9-ed16-4e15-d9cd-ef4bfa623bfc"
      },
      "source": [
        "COLAB_P = False\n",
        "if COLAB_P:\n",
        "  print(\"Upload your file, then read it with pd.read_csv()\")\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  fn = list(uploaded.keys())[0]\n",
        "  print(\"File is uploaded to \", fn)\n",
        "else:\n",
        "  print(\"Place your file to the same directory as the notebook, then read your file with pd.read_csv()\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Place your file to the same directory as the notebook, then read your file with pd.read_csv()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMsqdgKrYugR"
      },
      "source": [
        "# Load the data\n",
        "\n",
        "df = pd.read_csv(\"sea_ears.csv\",\n",
        " index_col=0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0P12NdQZPxw"
      },
      "source": [
        "# Observe top 10 observations (int)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhow8gCsZUyT"
      },
      "source": [
        "# Q1.1 What is the length of an abalone with id 986?\n",
        "# Q1.2 How many rings the fifth abalone with \"FN\" == \"Fresh\" has?\n",
        "# Q1.3 How many rings the sample with id 67 has?\n",
        "# Q1.4 What is the `Height` of a thirty fourth sample with `Rings` == 10?\n",
        "# Q1.5 How heavy as a whole is the female abalone #6?\n",
        "\n",
        "# Please note that for some questions there are several answers. If that's the \n",
        "# case, show all of them. Also for some, there is none. If so, show the shape \n",
        "# of returned series in your output.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXEj8wifdVjV"
      },
      "source": [
        "# Observe last 10 observations (int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ahNTahGdNhT"
      },
      "source": [
        "# Q2.1 What is the diameter of a tenth abalone with second name Flow?\n",
        "# Q2.2 What is the weight of a shell for 99-th abalone with first name Lil'?\n",
        "# Q2.3 How many rings twelfth abalone with first name MC' has?\n",
        "# Q2.4 How many rings the 666-th abalone has?\n",
        "# Q2.5 What is the gender of 1337-th abalone?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlx4DfDsdku4"
      },
      "source": [
        "# Increase maximal displayed columns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFRAlFOYdm9A"
      },
      "source": [
        "# Observe top 10 observations again\n",
        "# Is there any new columns displayed?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zui3i6ZOdo2D"
      },
      "source": [
        "# Print all the columns/features names (int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwPaHlDhuklP"
      },
      "source": [
        "# Q3.1 How many columns end with a vowel?\n",
        "# Q3.2 How many columns start with a vowel?\n",
        "# Q3.3 Which columns are associated with the weight of the clam?\n",
        "# Q3.4 How many columns have `th` in their names?\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka8e4hmZdqLp"
      },
      "source": [
        "# Print data size (int)\n",
        "\n",
        "# Q4.1 How many observations are in the data?\n",
        "# Q4.2 How many features are in the data?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWqFpMWPdy3E"
      },
      "source": [
        "# 2. Basic data exploration\n",
        "\n",
        "Lets do some basics:\n",
        "\n",
        "`.count()` number of not NaN's in every column.\n",
        "    \n",
        "Is there any missing values in the data?     \n",
        "Count number of unique values in every column .nunique().    \n",
        "What does this tells you about the features, which are most likely categorical and which are most likely numerical?    \n",
        "Use pandas `.describe()` to display basic statistic about the data.   \n",
        "Use pandas `.value_counts()` to count number of unique values in a specific column.   \n",
        "Use pandas `.min()`, `.max()`, `.mean()`, `.std()` to display specific statistics about the data.    \n",
        "Use pandas `.dtypes` field to display data types in columns. \n",
        "Hint You could use `.sort_index()` or `.sort_values()` to sort the result of `.value_counts()`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwlcBdvIwlfB"
      },
      "source": [
        "# Display number of not NaN's in every column (int)\n",
        "\n",
        "# Q5.1 How many NA values are in the `Whole` column?\n",
        "# Q5.2 How many NA values are in the `Rings` column?\n",
        "# Q5.3 How many NA values are in the `Viscera` column?\n",
        "# Q5.4 How many NA values are in the `FN` column?\n",
        "# Q5.5 How many explicit NA values are in the `Shell` column?\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCxMUIbnx-QD"
      },
      "source": [
        "# Count number of unique values in every column (int)\n",
        "\n",
        "# Q6.1 How many unique values are in the `FN` column?\n",
        "# Q6.2 How many unique values are in the `SN` column?\n",
        "# Q6.3 How many unique values are in the `Rings` column?\n",
        "# Q6.4 How many unique values are in the `Viscera` column?\n",
        "# Q6.5 How many unique values are in the `Shell` column?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPJMcqYQyD9y"
      },
      "source": [
        "# Count frequency of the values in different columns (list of ints in ascending order)\n",
        "# You could select a column using same syntax as for selecting a key from a dictionary: `data[colname]`\n",
        "\n",
        "# Q7.1 For every unique `FN` value give its number of occurences.\n",
        "# Q7.2 For every unique `SN` value give its number of occurences.\n",
        "# Q7.3 For every unique `Rings` value give its number of occurences.\n",
        "# Q7.4 For every unique `Sex` value give its number of occurences.\n",
        "# Q7.5 For every unique `LN` value give its number of occurences.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo6KibQ3x4Jw"
      },
      "source": [
        "# Display basic data statistics using .describe()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vIOZuv7yErp"
      },
      "source": [
        "# Display some column statistics (list of floats, rounded up to 3 digits, e.g. 1.234)\n",
        "\n",
        "# Q8.1 What are the max, min, mean and the std of the `Viscera` column?\n",
        "# Q8.2 What are the max, min, mean and the std of the `Rings` column?\n",
        "# Q8.3 What are the max, min, mean and the std of the `Length` column?\n",
        "# Q8.4 What are the max, min, mean and the std of the `Diam` column?\n",
        "# Q8.5 What are the max, min, mean and the std of the `Whole` column?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71Kx1GnoyG7v"
      },
      "source": [
        "# Display data types of all columns (int)\n",
        "\n",
        "# Q9.1 How many columns have `object` data type?\n",
        "# Q9.2 How many columns have `int64` data type?\n",
        "# Q9.3 How many columns have `float64` data type?\n",
        "\n",
        "# Display data types of all columns (list of str)\n",
        "# Q9.4 What are the columns with dtype == `float64`?\n",
        "# Q9.5 What are the columns with dtype == `int64`?\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPVevhAMtqVQ"
      },
      "source": [
        "df = df.dropna()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rrG2dQQe5yf"
      },
      "source": [
        "# 3. Data selection\n",
        "\n",
        "In pandas.DataFrame you could select\n",
        "\n",
        "  Row/s by position (integer number [0 .. number of rows - 1]) .iloc or by DataFrame.index .loc:   \n",
        "\n",
        "```\n",
        "  data.loc[0]  \n",
        "  data.loc[5:10]  \n",
        "  data.iloc[0]  \n",
        "  data.iloc[5:10]   \n",
        "```\n",
        "\n",
        "Though, this is probably the worst way to manipulate rows.   \n",
        "  Columns by name\n",
        "\n",
        "```\n",
        "  data[columname]\n",
        "```\n",
        "\n",
        "  Row/s and columns\n",
        "\n",
        "```\n",
        "  data.loc[10, columname]  \n",
        "  data.iloc[10, columname]  \n",
        "```\n",
        "\n",
        "Using boolean mask\n",
        "\n",
        "```\n",
        "  mask = data[columname] > value  \n",
        "  data[mask]  \n",
        "```\n",
        "\n",
        "You could combine multiple conditions using & or | (and, or)   \n",
        "\n",
        "```\n",
        "cond1 = data[columname1] > value1  \n",
        "cond2 = data[columname2] > value2  \n",
        "data[cond1 & cond2]  \n",
        "```\n",
        "\n",
        "Using queries .query():  \n",
        "\n",
        "```\n",
        "value = 5 \n",
        "data.query(\"columname > value\")  \n",
        "```\n",
        "\n",
        "You could combine multiple conditions using and, or  \n",
        "\n",
        "```\n",
        "data.query(\"(columname1 > value1) and (columname2 > value2)\")\n",
        "```\n",
        "\n",
        "and others. See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html for more examples.\n",
        "\n",
        "Remember to use different quotation marks \" or ' for columnname inside a query.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJnCqUx-0YRx"
      },
      "source": [
        "# Select rows by position (int) \n",
        "\n",
        "# Q10.1 What is the first name of a clam on row 777?\n",
        "# Q10.2 What is the last name of a clam on row 999?\n",
        "# Q10.3 How long is a clam from row 1337?\n",
        "# Q10.4 What is the gender of a clam from row 314?\n",
        "# Q10.5 When was the clam with row of 2718 captured?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv5jRoeU0aQG"
      },
      "source": [
        "# Select rows by index (int)\n",
        "\n",
        "# Q11.1 What is the gender of a clam with index 1102?\n",
        "# Q11.2 How long is a clam with index 5695?\n",
        "# Q11.3 How heavy is a clam with index 1045 when still alive?\n",
        "# Q11.4 When was the clam with index 252 captured?\n",
        "# Q11.5 What is the middle name of a clam with index 38?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZneqD6P0e5C"
      },
      "source": [
        "# Using mask or .query syntax select rows/columns (int)\n",
        "\n",
        "# Q12.1 How many clams have less than 5 rings?\n",
        "# Q12.2 When were clams named \"Boy Rock Killer\" captured?\n",
        "# Q12.3 How many clams have length more than 0.1?\n",
        "# Q12.4 How many clams are heavier (in shell) than 0.3?\n",
        "# Q12.5 How many clams were captured at 24 of July?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm4Ve-s70h73"
      },
      "source": [
        "# Using mask or .query syntax select rows/columns (int)\n",
        "\n",
        "# Q13.1 How many clams were captured in the fall? Including both start and end day.\n",
        "# Q13.2 How many clams that were captured in the fall, have first name \"Lil'\"?\n",
        "# Q13.3 How many clams that are wider than 0.4, have first name \"Monster\"?\n",
        "# Q13.4 What was the second name of a clam captured at March, 8, that that was longer than 0.65 and wider than 0.57?\n",
        "# Q13.5 How many rings does an infant clam that was captured in June and has shucked weight between 0.54 and 0.55 have?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTVitIYf0ib3"
      },
      "source": [
        "# Using mask or .query syntax select rows/columns and compute simple statistics (float)\n",
        "\n",
        "# Q14.1 What was the average whole weight of clams named \"Kitty\"?\n",
        "# Q14.2 What was the whole weight of the heaviest Lil' clam?\n",
        "# Q14.3 What was the weight of the lightest in terms of whole weight clam captured in June?\n",
        "# Q14.4 What is the median length of clams captured in April?\n",
        "# Q14.5 What is the minimum diameter of clams named \"Master\"?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBLabnN2fAPc"
      },
      "source": [
        "# 4. Creating new columns\n",
        "\n",
        "Creating new column of pandas.DataFrame is as easy as:\n",
        "```\n",
        "data['new_awesome_column'] = [] \n",
        "```\n",
        "that's it. But such a column is relatively useless. Typically, you would compute something new based on existing data and save it in a new column. For example one might want to compute total area of the house as a sum of all sqft_ columns, or create a boolean column of whether the house has grade > 2 or anything else:\n",
        "```\n",
        "data['total_area'] = data[col1] + data[col2] + ...\n",
        "data['high_value'] = data[col] > 5\n",
        "```\n",
        "Pandas also provides another powerfull tool: .apply, .map(), .applymap() methods (they are kinda the same, but not quite). https://stackoverflow.com/questions/19798153/difference-between-map-applymap-and-apply-methods-in-pandas . They allow you to apply some function to every value in the column/s (row-wise) or row (column-wise) or cell (element-wise). For example, same computations of total_area and high_value using .apply():\n",
        "```\n",
        "data['total_area'] = data[[col1, col2, col3]].apply(sum, axis=1)\n",
        "```\n",
        "you are not restricted to existent functions, .apply() accepts any function (including lambda functions):\n",
        "```\n",
        "data['total_area'] = data[[col1, col2, col3]].apply(lambda x: x[0]+x[1]+x[2], axis=1)\n",
        "```\n",
        "or ordinary python function (if this it should have complex behaviour):\n",
        "```\n",
        "def _sum(x):\n",
        "    total = 0\n",
        "    for elem in x:\n",
        "        total += elem\n",
        "    return total\n",
        "\n",
        "data['total_area'] = data[[col1, col2, col3]].apply(_sum, axis=1) \n",
        "```\n",
        "Many pandas methods has axis parameter axis=0 refers to rows, axis=1 refers to columns.\n",
        "\n",
        "Warning. You should never use for loops to sum numerical elements from the container."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC3VPe6sK_Pp"
      },
      "source": [
        "# create full_name column with concatenation of all clam names\n",
        "df['full_name'] = df['FN'] + df['SN'] + df['LN']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxbj9Po2Le18"
      },
      "source": [
        "# Create new columns using the old ones (new column in your DataFrame)\n",
        "\n",
        "# Q15.1 Create a `age_in_years` column (age is the number of rings +1.5) using any method above\n",
        "df['age_in_years'] = df['Rings'] + 1.5\n",
        "# Q15.2 Create a new column `area` using diameter, length and considering that a clam is a perfect rectangle\n",
        "df['area'] = df['Diam'] * df['Length']\n",
        "# Q15.3 Create a new column `density` by dividing volume (area multiplied by a fixed number of 0.05) by whole weight\n",
        "df['density'] = df['area'] * 0.05 / df['Whole']\n",
        "# Q15.4 Create a new column `age_cat` by splitting a `age` into 5 ([1..5]) distinct intervals: 0 < x <=20%,\n",
        "# 20% < x <= 40%, ... 80% < x <= 100% percentiles. You could use `.quantile()` to compute percentiles.\n",
        "first = df.quantile(0.2)['age_in_years']\n",
        "second = df.quantile(0.4)['age_in_years']\n",
        "third = df.quantile(0.6)['age_in_years']\n",
        "fourth = df.quantile(0.8)['age_in_years']\n",
        "#df['age_cat'] = ['1' if c <first else '2' c <second else '3' c< third else '4' c < fourth for c in df['age_in_years']]\n",
        "df['age_cat'] = [1 if c <first else 2 if c <second else 3 if c< third else 4 if  c < fourth else 5 for c in df['age_in_years']]\n",
        "\n",
        "# Q15.5 Create a new bool column `high_class` it is True if clam has the proportion of shell in whole clam more or equal to 1\n",
        "df['high_class'] = [True if df['Shell'].iloc[i]/df['Whole'].iloc[i] >= 1 else False for i in range(len(df))]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fzig1HmlL4rq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3763e3a1-7b25-4d89-83ec-f55f0bce609d"
      },
      "source": [
        "# Using mask or .query syntax select rows/columns (float)\n",
        "\n",
        "# Q16.1 What is the average age of the clam of the high_class(=True)?\n",
        "print(np.mean(df[df['high_class']]['age_in_years']))\n",
        "# Q16.2 What is the average area of the clam from highest age category?\n",
        "print(np.mean(df[df['age_cat']==5]['area']))\n",
        "# Q16.3 What is the maximal length amongst clams with the lowest age category?\n",
        "print(np.max(df[df['age_cat']==1]['Length']))\n",
        "# Q16.4 What is the most frequent gender amongst clams with the lowest age category?\n",
        "# Q16.5 What is the minimal number of rings in clams with high_class=True?\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.5\n",
            "0.2771957587669833\n",
            "0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezvSnhPRfFXM"
      },
      "source": [
        "# 5. Basic date processing\n",
        "\n",
        "You figure out that column date is to harsh for you, so you decided to convert it to a more plausible format:\n",
        "\n",
        "- Use pandas method to_datetime() to convert the date to a good format.\n",
        "- Extract year, month, day and weekday from your new date column. Save them to separete columns.\n",
        "- How many columns has your data now?\n",
        "- Drop column date, remember to set inplace parameter to True.\n",
        "\n",
        "Hint: for datetime formatted date you could extract the year as follow:\n",
        "```\n",
        "data.date.dt.year\n",
        "```\n",
        "Very often date could be a ridiculously rich feature, sometimes it is holidays that matters, sometimes weekends, sometimes some special days like black friday.\n",
        "\n",
        "Learn how to work with date in Python!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZghL5CmKTBZc"
      },
      "source": [
        "# Create new columns based on `Captured` column\n",
        "\n",
        "# Q17.1 Convert date to datetime format\n",
        "df['Captured'] = pd.to_datetime(df['Captured'])\n",
        "\n",
        "# Q17.2 Extract and store `year`\n",
        "df['year'] = df['Captured'].dt.year\n",
        "# Q17.3 Extract and store `month`\n",
        "df['month'] = df['Captured'].dt.month\n",
        "# Q17.4 Extract and store `day`\n",
        "df['day'] = df['Captured'].dt.day\n",
        "# Q17.5 Extract and store `weekday`\n",
        "df['weekday'] = df['Captured'].dt.weekday\n",
        "# Q17.6 Create a new column `age10` - the age of the clam in full decades (e.g. 9 year old clam - 0, 21 year old clam - 2)\n",
        "df['age10'] = df['age_in_years']//10\n",
        "from datetime import datetime\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcgZcfuITEZ4"
      },
      "source": [
        "# Drop column `Captured`\n",
        "\n",
        "del df[\"Captured\"]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU_wYcyETK9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d244d6ec-e734-4e6a-d965-3d4b9dfafeb4"
      },
      "source": [
        "# Find some date related information from the data (int)\n",
        "from collections import Counter\n",
        "# Q18.1 What is the most popular capturing weekday?\n",
        "weekdayFreqs = dict(Counter(df['weekday']))\n",
        "print(max(weekdayFreqs, key=lambda key: weekdayFreqs[key]) )\n",
        "# Q18.2 What is the most popular capturing month?\n",
        "# Q18.3 What is the least popular capturing weekday?\n",
        "print(min(weekdayFreqs, key=lambda key: weekdayFreqs[key]) )\n",
        "# Q18.4 What is the median age of the clam? (float)\n",
        "# Q18.5 How many clams were captured on the Day of Russia (June, 12)?\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LrPCPd0fRYz"
      },
      "source": [
        "# 6. Groupby\n",
        "\n",
        "from the documentation https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html\n",
        "\n",
        "By “group by” we are referring to a process involving one or more of the following steps:\n",
        "\n",
        "- Splitting the data into groups based on some criteria.\n",
        "- Applying a function to each group independently.\n",
        "- Combining the results into a data structure.\n",
        "\n",
        "`.groupby()` is one of the most powerfull tool for feature engineering. Very often it is used to group object with the same categorical characteristics and compute some statistics (e.g. mean, max, etc.) of a their numerical characteric.\n",
        "\n",
        "Instead of computing average area of houses with high grade you could compute average areas of the houses for every grade in a single command:\n",
        "```\n",
        "data.groupby('grade')['sqm_tot_area'].mean()\n",
        "```\n",
        "You could also make multi-column groups:\n",
        "```\n",
        "data.groupby(['weekday','grade'])['price'].min()\n",
        "```\n",
        "next, you could compute multiple aggregation functions:\n",
        "```\n",
        "data.groupby(['weekday','grade'])['price'].agg([min, max])\n",
        "```\n",
        "instead of using built-in functions you could compute custom functions using apply:\n",
        "```\n",
        "import numpy as np\n",
        "data.groupby(['condition','grade'])['bathrooms'].apply(lambda x: np.quantile(x, .5))\n",
        "```\n",
        "and the coolest thing now is that you can map the results of groupby back on your DataFrame!\n",
        "```\n",
        "gp = data.groupby(['condition'])['bathrooms'].median()\n",
        "data['gp_feature'] = data['condition'].map(gp)\n",
        "```\n",
        "Now, if some house has condition == 2, its gp_feature will be equal to the median number of bathrooms amongst all houses with condition == 2.\n",
        "\n",
        "Read more examples in the documentation https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRmmkfIVXp5K"
      },
      "source": [
        "# Create some groupby features\n",
        "\n",
        "# Q19.1 `whole_by_year` groupby `year` and compute median whole weight.\n",
        "# Q19.2 `shell_by_weekday` groupby `weekday` and compute median shell weight.\n",
        "\n",
        "gp = df.groupby('weekday')['Shell'].median()\n",
        "df['shell_by_weekday'] = df['weekday'].map(gp)\n",
        "# Q19.3 `area_by_age` groupby `age_cat` and compute average `area`.\n",
        "# Q19.4 `density_by_age` groupby `age_cat` and compute average density of a clam.\n",
        "gp  = df.groupby('age_cat')['density'].mean()\n",
        "df['density_by_age'] = df['age_cat'].map(gp)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIKPaeH_fIfj"
      },
      "source": [
        "# Create some other groupby features\n",
        "# for this task check out this answer:\n",
        "# https://stackoverflow.com/questions/47913343/how-to-groupby-and-map-by-two-columns-pandas-dataframe\n",
        "\n",
        "# Q20.1 `rings_fn` groupby `n_rings` and count average number of occurences of every unique first name\n",
        "\n",
        "# Q20.2 `n_month` groupby `month` and count number of captured in each month\n"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agb-hTSpnHeD",
        "outputId": "ad12fa6b-93f1-47ee-feb2-bd394b576f8b"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'FN', 'SN', 'LN', 'Sex', 'Length', 'Diam', 'Height', 'Whole',\n",
              "       'Shucke', 'Viscera', 'Shell', 'Rings', 'full_name', 'age_in_years',\n",
              "       'area', 'density', 'age_cat', 'high_class', 'year', 'month', 'day',\n",
              "       'weekday', 'age10', 'shell_by_weekday', 'density_by_age'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y3IX6U1fOVI"
      },
      "source": [
        "# 7. Building a regression model\n",
        "\n",
        "- You do not need to normalize data for tree models, and for linear/knn models this step is essential.\n",
        "- Remember, that not all of the features in the table are numeric, some of them might be viewed as categorical.\n",
        "-You may create or drop any features you want, except for the features which use age or number of rings (e.g. average number of rings from a clam of high class).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwdbUu2wYKpB"
      },
      "source": [
        "# Q21 Drop all generated features which used age or number of rings column, e.g. rings_month, age_cat.\n",
        "Y = df[\"age_in_years\"].values\n",
        "\n",
        "good_columns = ['id', 'FN', 'SN', 'LN', 'Sex', 'Length', 'Diam', 'Height', 'Whole',\n",
        "       'Shucke', 'Viscera', 'Shell', 'Rings', 'area', 'density']\n",
        "Xdf = df[good_columns]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kINHDN92rzUP"
      },
      "source": [
        "# Optionally create or drop any features \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "onehotencoder = OneHotEncoder()\n",
        "newXdf = onehotencoder.fit_transform(Xdf.iloc[:,1:5]).toarray()\n",
        "newXdf = pd.DataFrame(newXdf, index = Xdf.index)\n",
        "#Xdf =  pd.DataFrame(Xdf, index = Xdf['id'])\n",
        "colnames = {}\n",
        "j = 0\n",
        "for i in good_columns[1:5]:\n",
        "  uni = df[i].nunique()\n",
        "  \n",
        "  for l in range(uni):\n",
        "    colnames[j+l] = i\n",
        "  j += uni"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxeu3FkPi8fm",
        "outputId": "953c2f0f-3020-49af-cb8c-f11c6636da02"
      },
      "source": [
        "colnames"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'FN',\n",
              " 1: 'FN',\n",
              " 2: 'FN',\n",
              " 3: 'FN',\n",
              " 4: 'FN',\n",
              " 5: 'FN',\n",
              " 6: 'FN',\n",
              " 7: 'FN',\n",
              " 8: 'FN',\n",
              " 9: 'FN',\n",
              " 10: 'FN',\n",
              " 11: 'FN',\n",
              " 12: 'SN',\n",
              " 13: 'SN',\n",
              " 14: 'SN',\n",
              " 15: 'SN',\n",
              " 16: 'SN',\n",
              " 17: 'SN',\n",
              " 18: 'SN',\n",
              " 19: 'SN',\n",
              " 20: 'LN',\n",
              " 21: 'LN',\n",
              " 22: 'LN',\n",
              " 23: 'LN',\n",
              " 24: 'LN',\n",
              " 25: 'LN',\n",
              " 26: 'LN',\n",
              " 27: 'Sex',\n",
              " 28: 'Sex',\n",
              " 29: 'Sex'}"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_9eHkaVB_Bm"
      },
      "source": [
        "newXdf = pd.concat([Xdf, newXdf], axis = 1)\n",
        "#print(newXdf.shape)\n",
        "newXdf = newXdf.iloc[:, 6:]\n",
        "#print(newXdf.shape)\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdLqDhuCYO1Z"
      },
      "source": [
        "# Q22 Split your data into train and test parts.\n",
        "# How many records (rows) do you have in train and test tables? (list of int)?\n",
        "# Use sklearn.model_selection.train_test_split with test_size=0.33 and random_state=7\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "aim = df['Rings']+1.5\n",
        "train_ind, test_ind , y_train, y_test = train_test_split(newXdf, aim, test_size=0.33, random_state=7)\n",
        "newXdf.iloc[:,9:] = (newXdf.iloc[:,9:] - np.average(newXdf.iloc[:,9:], axis = 0)) / np.std(newXdf.iloc[:,9:], axis = 0)\n",
        "train_ind1, test_ind1, y_train1, y_test1 = train_test_split(newXdf, aim, test_size=0.33, random_state=7)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqubzK5rYQA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c328ed-0074-4007-b05a-c10bd1a4c77e"
      },
      "source": [
        "# Fit predictive regression models.\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "\n",
        "# Q23.1 Use linear regression with l2 regularization (Ridge regression)\n",
        "Ri = Ridge()\n",
        "Ri.fit(train_ind1,  y_train1)\n",
        "# Q23.2 Use decision tree regression\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "Tree = DecisionTreeRegressor(random_state=0) \n",
        "Tree.fit(train_ind,  y_train)\n",
        "# Q23.3 Use k nearest neighbours regression\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
              "                      max_features=None, max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                      random_state=0, splitter='best')"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uWxRty0YSBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abec99f7-ba20-48b2-9c5e-a35f228b4efe"
      },
      "source": [
        "# Use grid search to select optimal hyperparamters of your models.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Q24.1 Alpha for a ridge regression\n",
        "parameters = {'alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
        "Ri_param = Ridge()\n",
        "gridLinMod = GridSearchCV(Ri_param, parameters)\n",
        "gridLinMod.fit(train_ind1,  y_train1)\n",
        "best_alpha = gridLinMod.best_params_['alpha']\n",
        "print(best_alpha)\n",
        "\n",
        "# Q24.2 Depth for the tree\n",
        "\n",
        "parameters = {'max_depth':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
        "Tree_param = DecisionTreeRegressor() \n",
        "gridTreeMod = GridSearchCV(Tree_param, parameters)\n",
        "gridTreeMod.fit(train_ind,  y_train)\n",
        "best_depth = gridTreeMod.best_params_['max_depth']\n",
        "print(best_depth)\n",
        "# Q24.3 Number of neighbours for the knn\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1e-05\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVihHjlpYTrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a91351ec-7299-48c5-8285-cd22dbbf8141"
      },
      "source": [
        "# Compute train and test mean squared error for your best models (list of float).\n",
        "\n",
        "# Q25.1 Train, test MSE using linear regression with l2 regularization\n",
        "# Q25.2 Train, test MSE using decision tree regression\n",
        "# Q25.3 Train, test MSE using k nearest neighbours regression\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "Ri = Ridge(alpha = best_alpha)\n",
        "Ri.fit(train_ind1,  y_train1)\n",
        "y_pred = Ri.predict(train_ind1)\n",
        "\n",
        "print('For train(Ridge):', mean_squared_error(y_train1, y_pred))\n",
        "y_pred = Ri.predict(test_ind1)\n",
        "print('For test(Ridge):',  mean_squared_error(y_test1, y_pred))\n",
        "\n",
        "\n",
        "Tree = DecisionTreeRegressor(max_depth=best_depth) \n",
        "Tree.fit(train_ind,  y_train) \n",
        "\n",
        "y_pred = Tree.predict(train_ind)\n",
        "\n",
        "print('For train(Tree):', mean_squared_error(y_train, y_pred))\n",
        "\n",
        "\n",
        "y_pred = Tree.predict(test_ind)\n",
        "print('For test(Tree):', mean_squared_error(y_test, y_pred))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For train(Ridge): 2.7858298361174987e-18\n",
            "For test(Ridge): 2.965626785983001e-18\n",
            "For train(Tree): 0.0\n",
            "For test(Tree): 0.0036231884057971015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqwSIwVmYVZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd318c9-574b-48e8-af96-daf7519b256a"
      },
      "source": [
        "# Compute train and test R^2 for your best models (list of float).\n",
        "\n",
        "# Q26.1 Train, test R^2 using linear regression with l2 regularization\n",
        "# Q26.2 Train, test R^2 using decision tree regression\n",
        "# Q26.3 Train, test R^2 using k nearest neighbours regression\n",
        "\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "y_pred = Ri.predict(train_ind1)\n",
        "\n",
        "print('For train(Ridge):', pearsonr(y_train1, y_pred))\n",
        "y_pred = Ri.predict(test_ind1)\n",
        "print('For test(Ridge):',  pearsonr(y_test1, y_pred))\n",
        "\n",
        "\n",
        "y_pred = Tree.predict(train_ind)\n",
        "\n",
        "print('For train(Tree):', pearsonr(y_train, y_pred))\n",
        "y_pred = Tree.predict(test_ind)\n",
        "print('For test(Tree):', pearsonr(y_test, y_pred))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For train(Ridge): (1.0, 0.0)\n",
            "For test(Ridge): (0.9999999999999999, 0.0)\n",
            "For train(Tree): (1.0, 0.0)\n",
            "For test(Tree): (0.9998260160075543, 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO3zWCyHYXQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44c24a33-69fb-47dd-ce6c-18b3b9f22f42"
      },
      "source": [
        "# Q27 Which features have largest (by absolute value) weight in your linear model (top 5 features)? (list of str).\n",
        "arr1 = np.abs(Ri.coef_)\n",
        "arr2 = test_ind.columns\n",
        "arr1"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.57037318e-08, 4.99868912e-09, 6.10346172e-09, 1.37613599e-08,\n",
              "       6.26175286e-09, 1.03254447e-08, 9.99999999e-01, 1.59790499e-08,\n",
              "       5.31151794e-08, 5.90020583e-09, 6.00139275e-09, 5.92087897e-09,\n",
              "       6.07930629e-09, 5.89732354e-09, 6.07831583e-09, 6.20414774e-09,\n",
              "       6.28957683e-09, 6.02284154e-09, 5.96888223e-09, 6.13056257e-09,\n",
              "       5.92856068e-09, 2.27325403e-09, 2.24209236e-09, 2.26177890e-09,\n",
              "       2.34738340e-09, 2.24859102e-09, 2.26121547e-09, 2.25070996e-09,\n",
              "       2.24911489e-09, 2.49620200e-08, 2.52181440e-08, 2.58616633e-08,\n",
              "       2.43156583e-08, 2.56022233e-08, 2.59857934e-08, 2.50511548e-08,\n",
              "       3.05428244e-07, 3.07916537e-07, 3.17255567e-07])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G0eFwRbd4qL",
        "outputId": "4436279c-32f9-49f2-cac4-3d926b83f720"
      },
      "source": [
        "arr1inds = arr1.argsort()\n",
        "sorted_arr1 = arr1[arr1inds[::-1]]\n",
        "sorted_arr2 = arr2[arr1inds[::-1]]\n",
        "names = list()\n",
        "for i in range(len(sorted_arr2)):\n",
        "  if type(sorted_arr2[i]) == int:\n",
        "    if type(sorted_arr2[i-1])  != int or (colnames[sorted_arr2[i]] != colnames[sorted_arr2[i-1]]):\n",
        "      names.append(colnames[sorted_arr2[i]])\n",
        "  else:\n",
        "    names.append(sorted_arr2[i])\n",
        "\n",
        "print('Top 5 fiatures with the maximum absolute weight:', names[:5])\n"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 fiatures with the maximum absolute weight: ['Rings', 'Sex', 'density', 'LN', 'area']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G_LlOHofTJp"
      },
      "source": [
        "# Make sure your .ipynb is linearly executable     \n",
        "# Kernel -> Restart & Run All -> No ERROR cells"
      ]
    }
  ]
}